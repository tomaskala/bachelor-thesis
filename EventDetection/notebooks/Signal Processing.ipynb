{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from imp import reload\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import sklearn.mixture as gmm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import periodogram\n",
    "from scipy.stats import cauchy, entropy, norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from event_detection import data_fetchers, event_detector\n",
    "\n",
    "reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_time = time()\n",
    "debug = True\n",
    "\n",
    "t = time()\n",
    "documents, relative_days = data_fetchers.fetch_czech_corpus(num_docs=10000000)\n",
    "\n",
    "stream_length = max(relative_days) + 1  # Zero-based, hence the + 1.\n",
    "print('Read input in %fs.' % (time() - t))\n",
    "print('Stream length: %d' % stream_length)\n",
    "\n",
    "t = time()\n",
    "vectorizer = CountVectorizer(min_df=30, max_df=100000, binary=True, stop_words=event_detector.CZECH_STOPWORDS)\n",
    "bow_matrix = vectorizer.fit_transform(documents).tocsr()\n",
    "id2word = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "print('Created bag of words in %fs.' % (time() - t))\n",
    "print('BOW:', bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajectories = event_detector.construct_feature_trajectories(bow_matrix, relative_days, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dominant_period(signal):\n",
    "    freq, pgram = periodogram(signal)\n",
    "    \n",
    "    with np.errstate(divide='ignore'):\n",
    "        period = 1 / freq\n",
    "    \n",
    "    dps_index = np.argmax(pgram)\n",
    "    dp = period[dps_index]\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some incorrectly classified features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = ['predpis', 'pozadavek', 'vyzadat', 'mirny', 'narust', 'energie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.signal import convolve\n",
    "from scipy.signal import bartlett, blackman, gaussian, hamming, hanning, savgol_filter\n",
    "\n",
    "days = np.arange(stream_length)\n",
    "n_points = 15\n",
    "\n",
    "for error in errors:\n",
    "    fig = plt.figure()\n",
    "    word_id = vectorizer.vocabulary_[error]\n",
    "    signal = trajectories[word_id]\n",
    "    plt.plot(days, signal / signal.sum(), label=(error) + str(get_dominant_period(signal)))\n",
    "    \n",
    "#     window = bartlett(n_points, False)\n",
    "#     filtered = convolve(signal / signal.sum(), window / window.sum(), 'same')\n",
    "#     plt.plot(filtered / filtered.sum(), label=('Bartlett ' + str(get_dominant_period(filtered))))\n",
    "    \n",
    "#     window = blackman(n_points, False)\n",
    "#     filtered = convolve(signal / signal.sum(), window / window.sum(), 'same')\n",
    "#     plt.plot(filtered / filtered.sum(), label=('Blackman ' + str(get_dominant_period(filtered))))\n",
    "    \n",
    "#     window = hanning(n_points, False)\n",
    "#     filtered = convolve(signal / signal.sum(), window / window.sum(), 'same')\n",
    "#     plt.plot(filtered / filtered.sum(), label=('Hanning ' + str(get_dominant_period(filtered))))\n",
    "    \n",
    "#     window = gaussian(n_points, 2, False)\n",
    "#     filtered = convolve(signal / signal.sum(), window / window.sum(), 'same')\n",
    "#     plt.plot(filtered / filtered.sum(), label=('Gaussian ' + str(get_dominant_period(filtered))))\n",
    "    \n",
    "#     window = hamming(n_points, False)\n",
    "#     filtered = convolve(signal / signal.sum(), window / window.sum(), 'same')\n",
    "#     plt.plot(filtered / filtered.sum(), label=('Hamming ' + str(get_dominant_period(filtered))))\n",
    "    \n",
    "    filtered = savgol_filter(signal, 15, 3)\n",
    "    plt.plot(filtered / filtered.sum(), label=('SavGol ' + str(get_dominant_period(filtered))))\n",
    "\n",
    "    fig.set_size_inches(16, 10)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('DFIDF')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
