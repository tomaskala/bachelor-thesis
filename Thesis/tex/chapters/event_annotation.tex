After retrieving the event documents, we can use them to generate some sort of human-readable annotation of the individual events to present to the user. We aim to generate short summaries so that the user does not have to process a large quantity of text, and can just skim through a few sentences to decide whether he is interested in that particular event. If so, then he can examine it more closely and read the actual documents.

A simple approach is to annotate an event by the headline of the most relevant document in terms of Word Mover's Similarity. This assumes that a single document characterizes the whole set well enough to be used as a representant. Though this method does result in somewhat readable annotations, we also investigate a more complex approach.

The second method we use is based on a multi-document summarization system presented in \cite{multi-summarization-1, multi-summarization-2} and attempts to retrieve some number of highly relevant sentences to describe an event's document set. Again, we enrich this system by using word embeddings to measure sentence similarity, as in \cite{mogren-1}, as well as other similarity metrics \cite{mogren-2}.


\section{Multi-document summarization}
In \cite{multi-summarization-1}, the authors formulate the task of multi-document summarization as a combinatorial optimization problem, where the goal is to retrieve a subset of sentences maximizing a reward function $\quality{\cdot}$ under some constraints. The reward function measures the similarity of a summarization to the whole sentence set as well as diversity, so that two sentences do not carry duplicit information. The constraints limit the length of the resulting summary, either by total number of sentences or number of words.

In \cite{multi-summarization-1}, the authors laid out conditions under which a greedy algorithm finds a solution only a constant factor off the optimum and described a basic function satisfying these conditions. In \cite{multi-summarization-2}, a function better capturing sentence similarity and diversity was used.

Mathematically, the task is formulated as

\begin{equation}
\begin{alignedat}{-1}
\max_{S \subseteq V} & \quad \quality{S} = \coverage{S} + \lambda \diversity{S} \\
\text{s. t.} & \quad \sum_{i \in S}{\sentcost_{i}} \leq \budget,
\end{alignedat}
\end{equation}

where $V$ is the set of all sentences from the document set being summarized, $\sentcost_{i}$ is the cost of sentence $i$ (either 1 when limiting the number of sentences or the number of words in the sentence) and $\budget$ is the total budget.

The function $\coverage{\cdot}$ is a measure of how well does the summary cover the whole sentence set, and $\diversity{\cdot}$ is a measure of diversity, so that the sentences chosen for the summary do not carry redundant information. Both of these functions will be defined later, as we first need to define several of their components. The parameter $\lambda \geq 0$ can be used to control the diversity influence.


\section{Coverage function}

In \cite{multi-summarization-2}, the coverage function $\coverage{\cdot}$ is defined in terms of pairwise sentence similarity $\semsim{\cdot}{\cdot}$ as

\begin{equation}
\coverage{S} = \sum_{i \in V}{\min{\Big\{ \sum_{j \in S}{\semsim{i}{j}}, \alpha \sum_{k \in V}{\semsim{i}{k}} \Big\} }}.
\end{equation}

The first element of the minimum describes how similar $S$ is to $i$ -- how much of the sentence $i$ is covered by the summary $S$. The second element is then the largest possible value attainable. By discounting this largest possible value by an $0 \leq \alpha < 1$, more similar sentences to $i$ are allowed into $S$.

The authors further prove that if $\semsim{i}{j} \in [0,1]\ \forall i, j \in V$, the greedy algorithm still performs up to a constant factor close to the optimum.

Originally, only a simple cosine similarity between TFIDF sentence vectors \cite{information-retrieval} was used as $\semsim{\cdot}{\cdot}$. Kågebäck et al. examined various methods of word embeddings in \cite{mogren-1} to obtain a finer measure of similarity. This alone outperformed the original method, and in \cite{mogren-2}, a more complex system aggregating multiple similarity measures was built. We build on this method to add a few different similarity measures fit for event detection.

The resulting sentence similarity $\semsim{i}{j}$ will be computed as a product of the individual similarities, all bounded in $[0, 1]$: $\semsim{i}{j} = \prod_{l}{\similarity_{s_{i}s_{j}}^{l}}$.

Next, we define the individual sentence similarities used.

\subsection{TFIDF similarity}

\subsection{Word2Vec similarity}

\subsection{LSI similarity}

\subsection{TextRank similarity}

\subsection{Keyword similarity}

\subsection{Sentiment similarity}

\subsection{Temporal similarity}


\section{Diversity function}